{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-06-14T06:34:07.573255Z","iopub.status.busy":"2024-06-14T06:34:07.572539Z","iopub.status.idle":"2024-06-14T06:34:07.578082Z","shell.execute_reply":"2024-06-14T06:34:07.577096Z","shell.execute_reply.started":"2024-06-14T06:34:07.573225Z"},"trusted":true},"outputs":[],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T06:34:08.545642Z","iopub.status.busy":"2024-06-14T06:34:08.545295Z","iopub.status.idle":"2024-06-14T06:34:08.551488Z","shell.execute_reply":"2024-06-14T06:34:08.550554Z","shell.execute_reply.started":"2024-06-14T06:34:08.545614Z"},"trusted":true},"outputs":[],"source":["import torch\n","import random\n","\n","RANDOM_SEED = 42\n","torch.manual_seed(RANDOM_SEED)\n","random.seed(RANDOM_SEED)\n","np.random.seed(RANDOM_SEED)\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T06:34:10.148801Z","iopub.status.busy":"2024-06-14T06:34:10.147916Z","iopub.status.idle":"2024-06-14T06:34:14.701012Z","shell.execute_reply":"2024-06-14T06:34:14.699932Z","shell.execute_reply.started":"2024-06-14T06:34:10.148757Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8684ac1e378849fbb561c03135ede03c","version_major":2,"version_minor":0},"text/plain":["Downloading readme:   0%|          | 0.00/7.46k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"77f2468fbe5a49f3be5ec5e91aa2290d","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/699k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f8684a2aa4df4ac2a8c1ef9e0ab97784","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/90.0k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"29a9752c9c5d409080311f5d7249b579","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/92.2k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c16714059bcb4a848bc8c3eff69f95e0","version_major":2,"version_minor":0},"text/plain":["Generating train split:   0%|          | 0/8530 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ff987c7900474e19a3e00ac1922ef21a","version_major":2,"version_minor":0},"text/plain":["Generating validation split:   0%|          | 0/1066 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4a6e5226c63245cc94e2a7a1016427a7","version_major":2,"version_minor":0},"text/plain":["Generating test split:   0%|          | 0/1066 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from datasets import load_dataset\n","\n","dataset = load_dataset(\"cornell-movie-review-data/rotten_tomatoes\")"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T06:34:14.703140Z","iopub.status.busy":"2024-06-14T06:34:14.702644Z","iopub.status.idle":"2024-06-14T06:34:14.717043Z","shell.execute_reply":"2024-06-14T06:34:14.716105Z","shell.execute_reply.started":"2024-06-14T06:34:14.703112Z"},"trusted":true},"outputs":[],"source":["unique, counts = np.unique(dataset['train']['label'], return_counts=True)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T06:34:14.718845Z","iopub.status.busy":"2024-06-14T06:34:14.718534Z","iopub.status.idle":"2024-06-14T06:34:14.729798Z","shell.execute_reply":"2024-06-14T06:34:14.728908Z","shell.execute_reply.started":"2024-06-14T06:34:14.718820Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array([4265, 4265])"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["counts"]},{"cell_type":"markdown","metadata":{},"source":["Нет дисбаланса классов, их строго одинаковое количество. \n","\n","Поскольку нет дисбаланса классов и при этом классы равнозначны, т.е. цена ошибки на обоих классах одинакова, то будем в дальнейшем в качестве метрики классификации использовать accuracy"]},{"cell_type":"markdown","metadata":{},"source":["Перейдем к модели"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T06:34:14.732439Z","iopub.status.busy":"2024-06-14T06:34:14.731794Z","iopub.status.idle":"2024-06-14T06:34:19.724345Z","shell.execute_reply":"2024-06-14T06:34:19.723483Z","shell.execute_reply.started":"2024-06-14T06:34:14.732408Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c921d1581aea454c8efb858198e4bbe7","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"16ad2f9f58b64cb6b61658ae0461d152","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"de09af3471e34284b88872ef12ecd207","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"664f112da5c9415c972aaab5aa7fb693","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"62896052c2fc45a8b4b15321d01f9f7f","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from transformers import BertTokenizer, BertModel\n","\n","tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n","model = BertModel.from_pretrained(\"bert-base-cased\")"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T06:34:19.726042Z","iopub.status.busy":"2024-06-14T06:34:19.725555Z","iopub.status.idle":"2024-06-14T06:34:19.732195Z","shell.execute_reply":"2024-06-14T06:34:19.730997Z","shell.execute_reply.started":"2024-06-14T06:34:19.726016Z"},"trusted":true},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['text', 'label'],\n","        num_rows: 8530\n","    })\n","    validation: Dataset({\n","        features: ['text', 'label'],\n","        num_rows: 1066\n","    })\n","    test: Dataset({\n","        features: ['text', 'label'],\n","        num_rows: 1066\n","    })\n","})"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["dataset"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T06:34:19.734529Z","iopub.status.busy":"2024-06-14T06:34:19.734239Z","iopub.status.idle":"2024-06-14T06:34:19.742971Z","shell.execute_reply":"2024-06-14T06:34:19.742232Z","shell.execute_reply.started":"2024-06-14T06:34:19.734505Z"},"trusted":true},"outputs":[],"source":["def tokenize_function(example):\n","    return tokenizer(example[\"text\"])"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T06:34:19.744434Z","iopub.status.busy":"2024-06-14T06:34:19.744099Z","iopub.status.idle":"2024-06-14T06:34:29.483849Z","shell.execute_reply":"2024-06-14T06:34:29.482804Z","shell.execute_reply.started":"2024-06-14T06:34:19.744402Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fdc0593cc4384ef7805bef250848bac5","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/8530 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5266ff8ef04241b89be25f0bc916bc08","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/1066 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"60fa364475144b13b4a12a30c0a7d9e1","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/1066 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["tokenized_datasets = dataset.map(tokenize_function, batched=True)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T06:34:29.504365Z","iopub.status.busy":"2024-06-14T06:34:29.504096Z","iopub.status.idle":"2024-06-14T06:34:41.896079Z","shell.execute_reply":"2024-06-14T06:34:41.894923Z","shell.execute_reply.started":"2024-06-14T06:34:29.504341Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-06-14 06:34:33.070298: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-06-14 06:34:33.070402: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-06-14 06:34:33.185768: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["from transformers import DataCollatorWithPadding"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T06:34:41.898590Z","iopub.status.busy":"2024-06-14T06:34:41.897440Z","iopub.status.idle":"2024-06-14T06:34:41.903711Z","shell.execute_reply":"2024-06-14T06:34:41.902787Z","shell.execute_reply.started":"2024-06-14T06:34:41.898548Z"},"trusted":true},"outputs":[],"source":["data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T06:34:41.908326Z","iopub.status.busy":"2024-06-14T06:34:41.907973Z","iopub.status.idle":"2024-06-14T06:34:41.922082Z","shell.execute_reply":"2024-06-14T06:34:41.921200Z","shell.execute_reply.started":"2024-06-14T06:34:41.908295Z"},"trusted":true},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 8530\n","    })\n","    validation: Dataset({\n","        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 1066\n","    })\n","    test: Dataset({\n","        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 1066\n","    })\n","})"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["tokenized_datasets"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T06:34:41.923628Z","iopub.status.busy":"2024-06-14T06:34:41.923304Z","iopub.status.idle":"2024-06-14T06:34:41.945086Z","shell.execute_reply":"2024-06-14T06:34:41.944249Z","shell.execute_reply.started":"2024-06-14T06:34:41.923593Z"},"trusted":true},"outputs":[{"data":{"text/plain":["['labels', 'input_ids', 'token_type_ids', 'attention_mask']"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["tokenized_datasets = tokenized_datasets.remove_columns([\"text\"])\n","tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n","tokenized_datasets.set_format(\"torch\")\n","tokenized_datasets[\"train\"].column_names"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T06:34:41.946844Z","iopub.status.busy":"2024-06-14T06:34:41.946254Z","iopub.status.idle":"2024-06-14T06:34:41.952725Z","shell.execute_reply":"2024-06-14T06:34:41.951767Z","shell.execute_reply.started":"2024-06-14T06:34:41.946813Z"},"trusted":true},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 8530\n","    })\n","    validation: Dataset({\n","        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 1066\n","    })\n","    test: Dataset({\n","        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 1066\n","    })\n","})"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["tokenized_datasets"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T06:34:41.954463Z","iopub.status.busy":"2024-06-14T06:34:41.953856Z","iopub.status.idle":"2024-06-14T06:34:41.964458Z","shell.execute_reply":"2024-06-14T06:34:41.963597Z","shell.execute_reply.started":"2024-06-14T06:34:41.954440Z"},"trusted":true},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","train_dataloader = DataLoader(\n","    tokenized_datasets[\"train\"], shuffle=True, batch_size=8, collate_fn=data_collator\n",")\n","eval_dataloader = DataLoader(\n","    tokenized_datasets[\"validation\"], batch_size=8, collate_fn=data_collator\n",")"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T06:34:41.965784Z","iopub.status.busy":"2024-06-14T06:34:41.965479Z","iopub.status.idle":"2024-06-14T06:34:41.995893Z","shell.execute_reply":"2024-06-14T06:34:41.995051Z","shell.execute_reply.started":"2024-06-14T06:34:41.965755Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Device used: cuda.\n"]}],"source":["device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","print(\"Device used: {}.\".format(device))"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T06:34:41.997199Z","iopub.status.busy":"2024-06-14T06:34:41.996916Z","iopub.status.idle":"2024-06-14T06:34:42.158798Z","shell.execute_reply":"2024-06-14T06:34:42.158068Z","shell.execute_reply.started":"2024-06-14T06:34:41.997176Z"},"trusted":true},"outputs":[],"source":["from torch import nn\n","\n","in_features = 768\n","tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n","\n","class BertWithClassifier(nn.Module):\n","    def __init__(self, linear_size):\n","        super(BertWithClassifier, self).__init__()\n","        self.bert = BertModel.from_pretrained(\"bert-base-cased\")\n","        self.head = nn.Sequential(\n","            nn.Dropout(),\n","            nn.Linear(in_features=in_features, out_features=linear_size),\n","            nn.BatchNorm1d(num_features=linear_size),\n","            nn.Dropout(p=0.8),\n","            nn.Linear(in_features=linear_size, out_features=1),\n","            # nn.BatchNorm1d(num_features=1),\n","            nn.Sigmoid()\n","        )\n","        \n","    def forward(self, tokens, attention_mask):\n","        bert_output = self.bert(input_ids=tokens, attention_mask=attention_mask)\n","        y = self.head(bert_output[1]) \n","        return y\n","        \n","    def freeze_bert(self):\n","        for param in self.bert.named_parameters():\n","            param[1].requires_grad=False\n","    \n","    def unfreeze_bert(self):\n","        for param in self.bert.named_parameters():\n","            param[1].requires_grad=True\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["Пока потренируем только голову, это будет бейзлайном"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T06:34:42.160079Z","iopub.status.busy":"2024-06-14T06:34:42.159806Z","iopub.status.idle":"2024-06-14T06:34:42.165843Z","shell.execute_reply":"2024-06-14T06:34:42.164859Z","shell.execute_reply.started":"2024-06-14T06:34:42.160056Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epochs: 24\n","Learning rate: 0.000027\n","Batch size: 16\n","The number of hidden layers in the custom head: 8\n"]}],"source":["# parameters\n","num_of_epochs = 24\n","learning_rate = 27e-6\n","batch_size = 16\n","hidden_layers = 8\n","\n","print(\"Epochs: {}\".format(num_of_epochs))\n","print(\"Learning rate: {:.6f}\".format(learning_rate))\n","print(\"Batch size: {}\".format(batch_size))\n","print(\"The number of hidden layers in the custom head: {}\".format(hidden_layers))"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T06:34:42.167213Z","iopub.status.busy":"2024-06-14T06:34:42.166958Z","iopub.status.idle":"2024-06-14T06:34:42.913788Z","shell.execute_reply":"2024-06-14T06:34:42.912537Z","shell.execute_reply.started":"2024-06-14T06:34:42.167191Z"},"trusted":true},"outputs":[{"data":{"text/plain":["BertWithClassifier(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSdpaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (head): Sequential(\n","    (0): Dropout(p=0.5, inplace=False)\n","    (1): Linear(in_features=768, out_features=8, bias=True)\n","    (2): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (3): Dropout(p=0.8, inplace=False)\n","    (4): Linear(in_features=8, out_features=1, bias=True)\n","    (5): Sigmoid()\n","  )\n",")"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["model = BertWithClassifier(linear_size=hidden_layers)\n","model.to(device)"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T06:34:42.915436Z","iopub.status.busy":"2024-06-14T06:34:42.915057Z","iopub.status.idle":"2024-06-14T06:34:42.934421Z","shell.execute_reply":"2024-06-14T06:34:42.933604Z","shell.execute_reply.started":"2024-06-14T06:34:42.915404Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}],"source":["from transformers import AdamW\n","\n","\n","optimizer = AdamW(model.parameters(), lr=learning_rate)\n","loss_fn = nn.BCELoss()"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T06:34:42.935981Z","iopub.status.busy":"2024-06-14T06:34:42.935646Z","iopub.status.idle":"2024-06-14T06:34:42.942285Z","shell.execute_reply":"2024-06-14T06:34:42.941255Z","shell.execute_reply.started":"2024-06-14T06:34:42.935952Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["25608\n"]}],"source":["from transformers import get_scheduler\n","\n","num_training_steps = num_of_epochs * len(train_dataloader)\n","lr_scheduler = get_scheduler(\n","    \"linear\",\n","    optimizer=optimizer,\n","    num_warmup_steps=0,\n","    num_training_steps=num_training_steps,\n",")\n","print(num_training_steps)"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T06:34:42.943660Z","iopub.status.busy":"2024-06-14T06:34:42.943398Z","iopub.status.idle":"2024-06-14T06:34:42.953038Z","shell.execute_reply":"2024-06-14T06:34:42.952104Z","shell.execute_reply.started":"2024-06-14T06:34:42.943637Z"},"trusted":true},"outputs":[],"source":["model.train()\n","model.freeze_bert()"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-06-12T07:51:02.598565Z","iopub.status.busy":"2024-06-12T07:51:02.598305Z","iopub.status.idle":"2024-06-12T07:51:02.623310Z","shell.execute_reply":"2024-06-12T07:51:02.622454Z","shell.execute_reply.started":"2024-06-12T07:51:02.598541Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'labels': torch.Size([8]),\n"," 'input_ids': torch.Size([8, 49]),\n"," 'token_type_ids': torch.Size([8, 49]),\n"," 'attention_mask': torch.Size([8, 49])}"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["for batch in train_dataloader:\n","    break\n","{k: v.shape for k, v in batch.items()}"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T06:34:42.954322Z","iopub.status.busy":"2024-06-14T06:34:42.954042Z","iopub.status.idle":"2024-06-14T06:34:42.962357Z","shell.execute_reply":"2024-06-14T06:34:42.961530Z","shell.execute_reply.started":"2024-06-14T06:34:42.954301Z"},"trusted":true},"outputs":[],"source":["from tqdm.auto import tqdm"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-06-12T07:51:02.624594Z","iopub.status.busy":"2024-06-12T07:51:02.624342Z","iopub.status.idle":"2024-06-12T07:57:46.526811Z","shell.execute_reply":"2024-06-12T07:57:46.526047Z","shell.execute_reply.started":"2024-06-12T07:51:02.624571Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ac75b571f2d049e884f83d102e1e4d7d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/25608 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["\n","\n","progress_bar = tqdm(range(num_training_steps))\n","\n","model.train()\n","model.freeze_bert()\n","\n","for epoch in range(num_of_epochs):\n","    for batch in train_dataloader:\n","        batch = {k: v.to(device) for k, v in batch.items()}\n","        outputs = torch.flatten(model(tokens=batch['input_ids'], attention_mask=batch['attention_mask']))\n","        loss = loss_fn(outputs, batch['labels'].float())\n","        loss.backward()\n","\n","        optimizer.step()\n","        lr_scheduler.step()\n","        optimizer.zero_grad()\n","        progress_bar.update(1)"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T06:34:42.964181Z","iopub.status.busy":"2024-06-14T06:34:42.963487Z","iopub.status.idle":"2024-06-14T06:34:42.971931Z","shell.execute_reply":"2024-06-14T06:34:42.971100Z","shell.execute_reply.started":"2024-06-14T06:34:42.964149Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","from sklearn.metrics import f1_score, accuracy_score\n","\n","def eval_prediction(y_batch_actual, y_batch_predicted):\n","    \"\"\"Return batches of accuracy and f1 scores.\"\"\"\n","    y_batch_actual_np = y_batch_actual.cpu().detach().numpy()\n","    y_batch_predicted_np = np.round(y_batch_predicted.cpu().detach().numpy())\n","    \n","    acc = accuracy_score(y_true=y_batch_actual_np, y_pred=y_batch_predicted_np)\n","    f1 = f1_score(y_true=y_batch_actual_np, y_pred=y_batch_predicted_np, average='weighted')\n","    \n","    return acc, f1"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T19:42:09.873353Z","iopub.status.busy":"2024-06-13T19:42:09.872982Z","iopub.status.idle":"2024-06-13T19:42:24.034186Z","shell.execute_reply":"2024-06-13T19:42:24.032939Z","shell.execute_reply.started":"2024-06-13T19:42:09.873325Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  pid, fd = os.forkpty()\n"]},{"name":"stdout","output_type":"stream","text":["Collecting evaluate\n","  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\n","Requirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.19.2)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\n","Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.1)\n","Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.32.3)\n","Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.4)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\n","Requirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.3.1)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.23.2)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\n","Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (0.6)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.1)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.9.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.4)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n","Downloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: evaluate\n","Successfully installed evaluate-0.4.2\n"]}],"source":["!pip install evaluate"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-06-12T07:58:00.109262Z","iopub.status.busy":"2024-06-12T07:58:00.108909Z","iopub.status.idle":"2024-06-12T07:58:02.763596Z","shell.execute_reply":"2024-06-12T07:58:02.762684Z","shell.execute_reply.started":"2024-06-12T07:58:00.109231Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(0.6222014925373134, 0.7495407991676658)"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["model.eval()\n","model.freeze_bert()\n","\n","size = len(eval_dataloader)\n","f1, acc = 0, 0\n","\n","with torch.no_grad():\n","    for batch in eval_dataloader:\n","        batch = {k: v.to(device) for k, v in batch.items()}\n","        X = batch['input_ids']\n","        attention_mask = batch['attention_mask']\n","        y = batch['labels']\n","\n","        pred = model(tokens=X, attention_mask=attention_mask)\n","\n","        acc_batch, f1_batch = eval_prediction(y.float(), pred)                        \n","        acc += acc_batch\n","        f1 += f1_batch\n","\n","    acc = acc/size\n","    f1 = f1/size\n","\n","acc, f1"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-06-12T07:58:02.765221Z","iopub.status.busy":"2024-06-12T07:58:02.764868Z","iopub.status.idle":"2024-06-12T07:58:02.769523Z","shell.execute_reply":"2024-06-12T07:58:02.768448Z","shell.execute_reply.started":"2024-06-12T07:58:02.765187Z"},"trusted":true},"outputs":[],"source":["# model = BertWithClassifier(linear_size=hidden_layers)\n","# model.to(device)"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-06-12T07:58:02.771160Z","iopub.status.busy":"2024-06-12T07:58:02.770816Z","iopub.status.idle":"2024-06-12T08:22:51.995225Z","shell.execute_reply":"2024-06-12T08:22:51.994210Z","shell.execute_reply.started":"2024-06-12T07:58:02.771125Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8e0c029129734abb88ae6e3ffa1bf9af","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/25608 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from tqdm.auto import tqdm\n","\n","progress_bar = tqdm(range(num_training_steps))\n","\n","model.train()\n","model.unfreeze_bert()\n","\n","for epoch in range(num_of_epochs):\n","    for batch in train_dataloader:\n","        batch = {k: v.to(device) for k, v in batch.items()}\n","        outputs = torch.flatten(model(tokens=batch['input_ids'], attention_mask=batch['attention_mask']))\n","        loss = loss_fn(outputs, batch['labels'].float())\n","        loss.backward()\n","\n","        optimizer.step()\n","        lr_scheduler.step()\n","        optimizer.zero_grad()\n","        progress_bar.update(1)"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-06-12T08:22:51.996877Z","iopub.status.busy":"2024-06-12T08:22:51.996566Z","iopub.status.idle":"2024-06-12T08:22:54.622672Z","shell.execute_reply":"2024-06-12T08:22:54.621702Z","shell.execute_reply.started":"2024-06-12T08:22:51.996852Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(0.6231343283582089, 0.7514877742489693)"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["model.eval()\n","model.freeze_bert()\n","\n","size = len(eval_dataloader)\n","f1, acc = 0, 0\n","\n","with torch.no_grad():\n","    for batch in eval_dataloader:\n","        batch = {k: v.to(device) for k, v in batch.items()}\n","        X = batch['input_ids']\n","        attention_mask = batch['attention_mask']\n","        y = batch['labels']\n","\n","        pred = model(tokens=X, attention_mask=attention_mask)\n","\n","        acc_batch, f1_batch = eval_prediction(y.float(), pred)                        \n","        acc += acc_batch\n","        f1 += f1_batch\n","\n","    acc = acc/size\n","    f1 = f1/size\n","\n","acc, f1"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T06:34:44.701816Z","iopub.status.busy":"2024-06-14T06:34:44.701173Z","iopub.status.idle":"2024-06-14T06:34:44.709123Z","shell.execute_reply":"2024-06-14T06:34:44.708088Z","shell.execute_reply.started":"2024-06-14T06:34:44.701782Z"},"trusted":true},"outputs":[],"source":["def training_step(dataloader, model, optimizer, loss_fn, if_freeze_bert):\n","    \"\"\"Method to train the model\"\"\"\n","    \n","    model.train()\n","    model.freeze_bert() if if_freeze_bert else model.unfreeze_bert()\n","      \n","    epoch_loss = 0\n","    size = len(dataloader.dataset)\n"," \n","    for i, batch in enumerate(dataloader):        \n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['labels'].to(device)\n","    \n","        outputs = torch.flatten(model(tokens=input_ids, attention_mask=attention_mask))\n","                        \n","        optimizer.zero_grad()\n","        loss = loss_fn(outputs, labels.float())\n","        epoch_loss += loss.item()\n","        loss.backward()\n","        optimizer.step()"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T06:34:45.728984Z","iopub.status.busy":"2024-06-14T06:34:45.728629Z","iopub.status.idle":"2024-06-14T06:34:45.736168Z","shell.execute_reply":"2024-06-14T06:34:45.735192Z","shell.execute_reply.started":"2024-06-14T06:34:45.728956Z"},"trusted":true},"outputs":[],"source":["def validation_step(dataloader, model, loss_fn):\n","    \"\"\"Method to test the model's accuracy and loss on the validation set\"\"\"\n","    \n","    model.eval()\n","    model.freeze_bert()\n","    \n","    size = len(dataloader)\n","    f1, acc = 0, 0\n","    \n","    with torch.no_grad():\n","        for batch in dataloader:\n","            X = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            y = batch['labels'].to(device)\n","                  \n","            pred = model(tokens=X, attention_mask=attention_mask)\n","            \n","            acc_batch, f1_batch = eval_prediction(y.float(), pred)                        \n","            acc += acc_batch\n","            f1 += f1_batch\n","\n","        acc = acc/size\n","        f1 = f1/size\n","                \n","    return acc, f1"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-06-12T08:22:54.646692Z","iopub.status.busy":"2024-06-12T08:22:54.646410Z","iopub.status.idle":"2024-06-12T08:22:55.239423Z","shell.execute_reply":"2024-06-12T08:22:55.238557Z","shell.execute_reply.started":"2024-06-12T08:22:54.646669Z"},"trusted":true},"outputs":[{"data":{"text/plain":["BertWithClassifier(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSdpaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (head): Sequential(\n","    (0): Dropout(p=0.5, inplace=False)\n","    (1): Linear(in_features=768, out_features=8, bias=True)\n","    (2): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (3): Dropout(p=0.8, inplace=False)\n","    (4): Linear(in_features=8, out_features=1, bias=True)\n","    (5): Sigmoid()\n","  )\n",")"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["model = BertWithClassifier(linear_size=hidden_layers)\n","model.to(device)"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T06:34:47.849604Z","iopub.status.busy":"2024-06-14T06:34:47.848680Z","iopub.status.idle":"2024-06-14T06:34:47.855396Z","shell.execute_reply":"2024-06-14T06:34:47.854340Z","shell.execute_reply.started":"2024-06-14T06:34:47.849564Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epochs: 13\n","Learning rate: 0.000010\n","Batch size: 16\n","The number of hidden layers in the custom head: 8\n"]}],"source":["# parameters\n","# num_of_epochs = 24\n","num_of_epochs = 13\n","# learning_rate = 1e-6\n","learning_rate = 1e-5\n","batch_size = 16\n","hidden_layers = 8\n","\n","print(\"Epochs: {}\".format(num_of_epochs))\n","print(\"Learning rate: {:.6f}\".format(learning_rate))\n","print(\"Batch size: {}\".format(batch_size))\n","print(\"The number of hidden layers in the custom head: {}\".format(hidden_layers))"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T06:34:49.277176Z","iopub.status.busy":"2024-06-14T06:34:49.276460Z","iopub.status.idle":"2024-06-14T06:34:49.284984Z","shell.execute_reply":"2024-06-14T06:34:49.284135Z","shell.execute_reply.started":"2024-06-14T06:34:49.277143Z"},"trusted":true},"outputs":[],"source":["optimizer = AdamW(model.parameters(), lr=learning_rate)\n","loss_fn = nn.BCELoss()"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2024-06-12T08:22:55.276534Z","iopub.status.busy":"2024-06-12T08:22:55.276293Z","iopub.status.idle":"2024-06-12T08:38:09.521414Z","shell.execute_reply":"2024-06-12T08:38:09.520544Z","shell.execute_reply.started":"2024-06-12T08:22:55.276513Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4ea26bbc3ffa40a6ad0ce2fa98d4f120","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/13 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch: #1\n","Bert is freezed\n","Training results: \n","Acc: 0.502, f1: 0.358\n","Validation results: \n","Acc: 0.507, f1: 0.510\n","Epoch: #2\n","Bert is freezed\n","Training results: \n","Acc: 0.513, f1: 0.381\n","Validation results: \n","Acc: 0.511, f1: 0.526\n","Epoch: #3\n","Bert is freezed\n","Training results: \n","Acc: 0.544, f1: 0.455\n","Validation results: \n","Acc: 0.556, f1: 0.614\n","Epoch: #4\n","Bert is freezed\n","Training results: \n","Acc: 0.554, f1: 0.479\n","Validation results: \n","Acc: 0.564, f1: 0.634\n","Epoch: #5\n","Bert is freezed\n","Training results: \n","Acc: 0.553, f1: 0.476\n","Validation results: \n","Acc: 0.560, f1: 0.626\n","Epoch: #6\n","Bert is not freezed\n","Training results: \n","Acc: 0.886, f1: 0.885\n","Validation results: \n","Acc: 0.839, f1: 0.906\n","Epoch: #7\n","Bert is not freezed\n","Training results: \n","Acc: 0.906, f1: 0.905\n","Validation results: \n","Acc: 0.834, f1: 0.902\n","Epoch: #8\n","Bert is not freezed\n","Training results: \n","Acc: 0.944, f1: 0.944\n","Validation results: \n","Acc: 0.866, f1: 0.923\n","Epoch: #9\n","Bert is not freezed\n","Training results: \n","Acc: 0.947, f1: 0.948\n","Validation results: \n","Acc: 0.844, f1: 0.907\n","Epoch: #10\n","Bert is not freezed\n","Training results: \n","Acc: 0.969, f1: 0.969\n","Validation results: \n","Acc: 0.826, f1: 0.897\n","Epoch: #11\n","Bert is not freezed\n","Training results: \n","Acc: 0.983, f1: 0.982\n","Validation results: \n","Acc: 0.856, f1: 0.918\n","Epoch: #12\n","Bert is not freezed\n","Training results: \n","Acc: 0.985, f1: 0.985\n","Validation results: \n","Acc: 0.868, f1: 0.925\n","Epoch: #13\n","Bert is not freezed\n","Training results: \n","Acc: 0.988, f1: 0.988\n","Validation results: \n","Acc: 0.847, f1: 0.912\n"]}],"source":["from tqdm.auto import tqdm\n","\n","tqdm.pandas()\n","\n","best_acc, best_f1 = 0, 0\n","path = './best_model.pt'\n","if_freeze_bert = False\n","\n","for i in tqdm(range(num_of_epochs)):\n","    print(\"Epoch: #{}\".format(i+1))\n","\n","    if i < 5:\n","        if_freeze_bert = True\n","        print(\"Bert is freezed\")\n","    else:\n","        if_freeze_bert = False\n","        print(\"Bert is not freezed\")\n","    \n","    training_step(train_dataloader, model,optimizer, loss_fn, if_freeze_bert)\n","    train_acc, train_f1 = validation_step(train_dataloader, model, loss_fn)\n","    val_acc, val_f1 = validation_step(eval_dataloader, model, loss_fn)\n","    \n","    print(\"Training results: \")\n","    print(\"Acc: {:.3f}, f1: {:.3f}\".format(train_acc, train_f1))\n","    \n","    print(\"Validation results: \")\n","    print(\"Acc: {:.3f}, f1: {:.3f}\".format(val_acc, val_f1))\n","    \n","    if val_acc > best_acc:\n","        best_acc = val_acc    \n","        torch.save(model, path)"]},{"cell_type":"markdown","metadata":{},"source":["Для базового Embedding MixUp буду опираться на эту статью: https://aclanthology.org/2020.coling-main.305.pdf\n","\n","Эмбеддинги смешиваются на выходе из пулера берта, перед подачей в классификационную голову. "]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2024-06-12T08:38:09.522982Z","iopub.status.busy":"2024-06-12T08:38:09.522677Z","iopub.status.idle":"2024-06-12T08:38:09.528679Z","shell.execute_reply":"2024-06-12T08:38:09.527806Z","shell.execute_reply.started":"2024-06-12T08:38:09.522957Z"},"trusted":true},"outputs":[{"data":{"text/plain":["0.8684701492537313"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["best_acc"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2024-06-12T08:38:09.530089Z","iopub.status.busy":"2024-06-12T08:38:09.529849Z","iopub.status.idle":"2024-06-12T08:38:09.537711Z","shell.execute_reply":"2024-06-12T08:38:09.536802Z","shell.execute_reply.started":"2024-06-12T08:38:09.530067Z"},"trusted":true},"outputs":[],"source":["# next(iter(train_dataloader))['input_ids'].shape"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T06:34:54.230983Z","iopub.status.busy":"2024-06-14T06:34:54.230299Z","iopub.status.idle":"2024-06-14T06:34:54.392505Z","shell.execute_reply":"2024-06-14T06:34:54.391748Z","shell.execute_reply.started":"2024-06-14T06:34:54.230949Z"},"trusted":true},"outputs":[],"source":["from torch import nn\n","\n","in_features = 768\n","tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n","\n","class BertWithClassifierMixUp(nn.Module):\n","    def __init__(self, linear_size):\n","        super(BertWithClassifierMixUp, self).__init__()\n","        self.bert = BertModel.from_pretrained(\"bert-base-cased\")\n","        self.head = nn.Sequential(\n","            nn.Dropout(),\n","            nn.Linear(in_features=in_features, out_features=linear_size),\n","            nn.BatchNorm1d(num_features=linear_size),\n","            nn.Dropout(p=0.8),\n","            nn.Linear(in_features=linear_size, out_features=1),\n","            # nn.BatchNorm1d(num_features=1),\n","            nn.Sigmoid()\n","        )\n","        \n","    def forward(self, tokens, attention_mask):\n","        bert_output = self.bert(input_ids=tokens, attention_mask=attention_mask)\n","        y = self.head(bert_output[1]) \n","        return y\n","    \n","    def forward_mixup(self, tokens1, attention_mask1, tokens2, attention_mask2, lam):\n","        bert_output1 = self.bert(input_ids=tokens1, attention_mask=attention_mask1)\n","        bert_output2 = self.bert(input_ids=tokens2, attention_mask=attention_mask2)\n","    \n","        bert_output = lam * bert_output1[1] + (1.0 - lam) * bert_output2[1]\n","    \n","        y = self.head(bert_output) \n","        return y\n","        \n","    def freeze_bert(self):\n","        for param in self.bert.named_parameters():\n","            param[1].requires_grad=False\n","    \n","    def unfreeze_bert(self):\n","        for param in self.bert.named_parameters():\n","            param[1].requires_grad=True\n","\n"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T06:34:55.816753Z","iopub.status.busy":"2024-06-14T06:34:55.816047Z","iopub.status.idle":"2024-06-14T06:34:55.825494Z","shell.execute_reply":"2024-06-14T06:34:55.824451Z","shell.execute_reply.started":"2024-06-14T06:34:55.816711Z"},"trusted":true},"outputs":[],"source":["def training_step_with_mixup(dataloader, model, optimizer, loss_fn, if_freeze_bert, lam):\n","    \"\"\"Method to train the model\"\"\"\n","    \n","    model.train()\n","    model.freeze_bert() if if_freeze_bert else model.unfreeze_bert()\n","      \n","    epoch_loss = 0\n","    size = len(dataloader.dataset)\n"," \n","    for i, batch in enumerate(dataloader):\n","        \n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['labels'].to(device)\n","\n","#         batch2 = next(iter(dataloader))\n","#         input_ids2 = batch2['input_ids'].to(device)\n","#         attention_mask2 = batch2['attention_mask'].to(device)\n","#         labels2 = batch2['labels'].to(device)\n","        \n","#         print(input_ids.shape)\n","#         print(attention_mask.shape)\n","#         print(labels.shape)\n","        \n","    \n","        model_answer = model.forward_mixup(input_ids, attention_mask, torch.flip(input_ids, dims=(0,)), torch.flip(attention_mask, dims=(0,)), lam)\n","    \n","        outputs = torch.flatten(model_answer)\n","        \n","        mixup_labels = lam * labels.float() + (1.0 - lam) * torch.flip(labels.float(), dims=(0,))\n","        \n","        optimizer.zero_grad()\n","        loss = loss_fn(outputs, mixup_labels)\n","        epoch_loss += loss.item()\n","        loss.backward()\n","        optimizer.step()"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2024-06-12T08:38:09.753377Z","iopub.status.busy":"2024-06-12T08:38:09.753095Z","iopub.status.idle":"2024-06-12T08:38:10.299263Z","shell.execute_reply":"2024-06-12T08:38:10.298349Z","shell.execute_reply.started":"2024-06-12T08:38:09.753351Z"},"trusted":true},"outputs":[{"data":{"text/plain":["BertWithClassifierMixUp(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSdpaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (head): Sequential(\n","    (0): Dropout(p=0.5, inplace=False)\n","    (1): Linear(in_features=768, out_features=8, bias=True)\n","    (2): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (3): Dropout(p=0.8, inplace=False)\n","    (4): Linear(in_features=8, out_features=1, bias=True)\n","    (5): Sigmoid()\n","  )\n",")"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["\n","model_mixup = BertWithClassifierMixUp(linear_size=hidden_layers)\n","model_mixup.to(device)"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T19:37:51.014083Z","iopub.status.busy":"2024-06-13T19:37:51.013718Z","iopub.status.idle":"2024-06-13T19:37:51.059896Z","shell.execute_reply":"2024-06-13T19:37:51.058706Z","shell.execute_reply.started":"2024-06-13T19:37:51.014053Z"},"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'model_mixup' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m AdamW(\u001b[43mmodel_mixup\u001b[49m\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate)\n\u001b[1;32m      2\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mBCELoss()\n","\u001b[0;31mNameError\u001b[0m: name 'model_mixup' is not defined"]}],"source":["optimizer = AdamW(model_mixup.parameters(), lr=learning_rate)\n","loss_fn = nn.BCELoss()"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2024-06-12T08:38:10.311687Z","iopub.status.busy":"2024-06-12T08:38:10.311393Z","iopub.status.idle":"2024-06-12T09:01:03.311253Z","shell.execute_reply":"2024-06-12T09:01:03.310268Z","shell.execute_reply.started":"2024-06-12T08:38:10.311657Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cba76c986945478e9182293a826c54d3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/13 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch: #1\n","Bert is freezed\n","Training results: \n","Acc: 0.565, f1: 0.496\n","Validation results: \n","Acc: 0.583, f1: 0.655\n","Epoch: #2\n","Bert is freezed\n","Training results: \n","Acc: 0.609, f1: 0.609\n","Validation results: \n","Acc: 0.597, f1: 0.725\n","Epoch: #3\n","Bert is freezed\n","Training results: \n","Acc: 0.591, f1: 0.578\n","Validation results: \n","Acc: 0.580, f1: 0.694\n","Epoch: #4\n","Bert is freezed\n","Training results: \n","Acc: 0.609, f1: 0.608\n","Validation results: \n","Acc: 0.608, f1: 0.738\n","Epoch: #5\n","Bert is freezed\n","Training results: \n","Acc: 0.618, f1: 0.609\n","Validation results: \n","Acc: 0.615, f1: 0.739\n","Epoch: #6\n","Bert is not freezed\n","Training results: \n","Acc: 0.860, f1: 0.860\n","Validation results: \n","Acc: 0.825, f1: 0.896\n","Epoch: #7\n","Bert is not freezed\n","Training results: \n","Acc: 0.895, f1: 0.894\n","Validation results: \n","Acc: 0.840, f1: 0.905\n","Epoch: #8\n","Bert is not freezed\n","Training results: \n","Acc: 0.918, f1: 0.918\n","Validation results: \n","Acc: 0.851, f1: 0.913\n","Epoch: #9\n","Bert is not freezed\n","Training results: \n","Acc: 0.930, f1: 0.930\n","Validation results: \n","Acc: 0.835, f1: 0.902\n","Epoch: #10\n","Bert is not freezed\n","Training results: \n","Acc: 0.935, f1: 0.934\n","Validation results: \n","Acc: 0.837, f1: 0.901\n","Epoch: #11\n","Bert is not freezed\n","Training results: \n","Acc: 0.963, f1: 0.963\n","Validation results: \n","Acc: 0.841, f1: 0.908\n","Epoch: #12\n","Bert is not freezed\n","Training results: \n","Acc: 0.972, f1: 0.972\n","Validation results: \n","Acc: 0.857, f1: 0.918\n","Epoch: #13\n","Bert is not freezed\n","Training results: \n","Acc: 0.975, f1: 0.975\n","Validation results: \n","Acc: 0.853, f1: 0.914\n"]}],"source":["from tqdm.auto import tqdm\n","\n","tqdm.pandas()\n","\n","best_acc, best_f1 = 0, 0\n","path = './best_model.pt'\n","if_freeze_bert = False\n","lam = 1\n","\n","for i in tqdm(range(num_of_epochs)):\n","    print(\"Epoch: #{}\".format(i+1))\n","\n","    if i < 5:\n","        if_freeze_bert = True\n","        print(\"Bert is freezed\")\n","        lam = 1\n","    else:\n","        if_freeze_bert = False\n","        lam = 0.7\n","        print(\"Bert is not freezed\")\n","    \n","    training_step_with_mixup(train_dataloader, model_mixup, optimizer, loss_fn, if_freeze_bert, lam)\n","    train_acc, train_f1 = validation_step(train_dataloader, model_mixup, loss_fn)\n","    val_acc, val_f1 = validation_step(eval_dataloader, model_mixup, loss_fn)\n","    \n","    print(\"Training results: \")\n","    print(\"Acc: {:.3f}, f1: {:.3f}\".format(train_acc, train_f1))\n","    \n","    print(\"Validation results: \")\n","    print(\"Acc: {:.3f}, f1: {:.3f}\".format(val_acc, val_f1))\n","    \n","    if val_acc > best_acc:\n","        best_acc = val_acc    \n","        torch.save(model, path)"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2024-06-12T09:01:03.312637Z","iopub.status.busy":"2024-06-12T09:01:03.312367Z","iopub.status.idle":"2024-06-12T09:01:03.318597Z","shell.execute_reply":"2024-06-12T09:01:03.317730Z","shell.execute_reply.started":"2024-06-12T09:01:03.312612Z"},"trusted":true},"outputs":[{"data":{"text/plain":["0.8572761194029851"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["best_acc"]},{"cell_type":"code","execution_count":50,"metadata":{"execution":{"iopub.execute_input":"2024-06-12T09:57:44.259399Z","iopub.status.busy":"2024-06-12T09:57:44.258748Z","iopub.status.idle":"2024-06-12T10:20:36.621989Z","shell.execute_reply":"2024-06-12T10:20:36.620994Z","shell.execute_reply.started":"2024-06-12T09:57:44.259368Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"486f64796dba4036a1ffa69cb3f21559","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/13 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch: #1\n","Bert is freezed\n","Training results: \n","Acc: 0.492, f1: 0.359\n","Validation results: \n","Acc: 0.503, f1: 0.516\n","Epoch: #2\n","Bert is freezed\n","Training results: \n","Acc: 0.501, f1: 0.356\n","Validation results: \n","Acc: 0.497, f1: 0.496\n","Epoch: #3\n","Bert is freezed\n","Training results: \n","Acc: 0.534, f1: 0.440\n","Validation results: \n","Acc: 0.525, f1: 0.564\n","Epoch: #4\n","Bert is freezed\n","Training results: \n","Acc: 0.557, f1: 0.494\n","Validation results: \n","Acc: 0.552, f1: 0.628\n","Epoch: #5\n","Bert is freezed\n","Training results: \n","Acc: 0.574, f1: 0.534\n","Validation results: \n","Acc: 0.563, f1: 0.653\n","Epoch: #6\n","Bert is not freezed\n","Training results: \n","Acc: 0.873, f1: 0.873\n","Validation results: \n","Acc: 0.835, f1: 0.903\n","Epoch: #7\n","Bert is not freezed\n","Training results: \n","Acc: 0.908, f1: 0.908\n","Validation results: \n","Acc: 0.838, f1: 0.907\n","Epoch: #8\n","Bert is not freezed\n","Training results: \n","Acc: 0.928, f1: 0.928\n","Validation results: \n","Acc: 0.850, f1: 0.913\n","Epoch: #9\n","Bert is not freezed\n","Training results: \n","Acc: 0.945, f1: 0.945\n","Validation results: \n","Acc: 0.855, f1: 0.917\n","Epoch: #10\n","Bert is not freezed\n","Training results: \n","Acc: 0.963, f1: 0.963\n","Validation results: \n","Acc: 0.847, f1: 0.912\n","Epoch: #11\n","Bert is not freezed\n","Training results: \n","Acc: 0.972, f1: 0.972\n","Validation results: \n","Acc: 0.852, f1: 0.915\n","Epoch: #12\n","Bert is not freezed\n","Training results: \n","Acc: 0.974, f1: 0.975\n","Validation results: \n","Acc: 0.854, f1: 0.916\n","Epoch: #13\n","Bert is not freezed\n","Training results: \n","Acc: 0.979, f1: 0.979\n","Validation results: \n","Acc: 0.851, f1: 0.914\n"]},{"data":{"text/plain":["0.855410447761194"]},"execution_count":50,"metadata":{},"output_type":"execute_result"}],"source":["model_mixup = BertWithClassifierMixUp(linear_size=hidden_layers)\n","model_mixup.to(device)\n","optimizer = AdamW(model_mixup.parameters(), lr=learning_rate)\n","loss_fn = nn.BCELoss()\n","\n","tqdm.pandas()\n","\n","best_acc, best_f1 = 0, 0\n","path = './best_model.pt'\n","if_freeze_bert = False\n","lam = 1\n","\n","for i in tqdm(range(num_of_epochs)):\n","    print(\"Epoch: #{}\".format(i+1))\n","\n","    if i < 5:\n","        if_freeze_bert = True\n","        print(\"Bert is freezed\")\n","        lam = 1\n","    else:\n","        if_freeze_bert = False\n","        lam = 0.85\n","        print(\"Bert is not freezed\")\n","    \n","    training_step_with_mixup(train_dataloader, model_mixup, optimizer, loss_fn, if_freeze_bert, lam)\n","    train_acc, train_f1 = validation_step(train_dataloader, model_mixup, loss_fn)\n","    val_acc, val_f1 = validation_step(eval_dataloader, model_mixup, loss_fn)\n","    \n","    print(\"Training results: \")\n","    print(\"Acc: {:.3f}, f1: {:.3f}\".format(train_acc, train_f1))\n","    \n","    print(\"Validation results: \")\n","    print(\"Acc: {:.3f}, f1: {:.3f}\".format(val_acc, val_f1))\n","    \n","    if val_acc > best_acc:\n","        best_acc = val_acc    \n","        torch.save(model, path)\n","        \n","best_acc"]},{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2024-06-12T09:26:23.402944Z","iopub.status.busy":"2024-06-12T09:26:23.402636Z","iopub.status.idle":"2024-06-12T09:51:46.579331Z","shell.execute_reply":"2024-06-12T09:51:46.578432Z","shell.execute_reply.started":"2024-06-12T09:26:23.402919Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1b0cc2ef40964f239a9eb09ec7dd5e82","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/13 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch: #1\n","Bert is freezed\n","Training results: \n","Acc: 0.500, f1: 0.353\n","Validation results: \n","Acc: 0.503, f1: 0.502\n","Epoch: #2\n","Bert is freezed\n","Training results: \n","Acc: 0.506, f1: 0.366\n","Validation results: \n","Acc: 0.505, f1: 0.511\n","Epoch: #3\n","Bert is freezed\n","Training results: \n","Acc: 0.531, f1: 0.421\n","Validation results: \n","Acc: 0.535, f1: 0.574\n","Epoch: #4\n","Bert is not freezed\n","Training results: \n","Acc: 0.822, f1: 0.822\n","Validation results: \n","Acc: 0.815, f1: 0.890\n","Epoch: #5\n","Bert is not freezed\n","Training results: \n","Acc: 0.866, f1: 0.866\n","Validation results: \n","Acc: 0.827, f1: 0.897\n","Epoch: #6\n","Bert is not freezed\n","Training results: \n","Acc: 0.886, f1: 0.886\n","Validation results: \n","Acc: 0.835, f1: 0.902\n","Epoch: #7\n","Bert is not freezed\n","Training results: \n","Acc: 0.902, f1: 0.902\n","Validation results: \n","Acc: 0.844, f1: 0.908\n","Epoch: #8\n","Bert is not freezed\n","Training results: \n","Acc: 0.924, f1: 0.924\n","Validation results: \n","Acc: 0.844, f1: 0.910\n","Epoch: #9\n","Bert is not freezed\n","Training results: \n","Acc: 0.938, f1: 0.938\n","Validation results: \n","Acc: 0.846, f1: 0.910\n","Epoch: #10\n","Bert is not freezed\n","Training results: \n","Acc: 0.944, f1: 0.944\n","Validation results: \n","Acc: 0.853, f1: 0.915\n","Epoch: #11\n","Bert is not freezed\n","Training results: \n","Acc: 0.955, f1: 0.955\n","Validation results: \n","Acc: 0.846, f1: 0.910\n","Epoch: #12\n","Bert is not freezed\n","Training results: \n","Acc: 0.963, f1: 0.963\n","Validation results: \n","Acc: 0.838, f1: 0.905\n","Epoch: #13\n","Bert is not freezed\n","Training results: \n","Acc: 0.966, f1: 0.966\n","Validation results: \n","Acc: 0.839, f1: 0.906\n"]},{"data":{"text/plain":["0.8526119402985075"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["model_mixup = BertWithClassifierMixUp(linear_size=hidden_layers)\n","model_mixup.to(device)\n","optimizer = AdamW(model_mixup.parameters(), lr=learning_rate)\n","loss_fn = nn.BCELoss()\n","\n","tqdm.pandas()\n","\n","best_acc, best_f1 = 0, 0\n","path = './best_model.pt'\n","if_freeze_bert = False\n","lam = 1\n","\n","for i in tqdm(range(num_of_epochs)):\n","    print(\"Epoch: #{}\".format(i+1))\n","\n","    if i < 3:\n","        if_freeze_bert = True\n","        print(\"Bert is freezed\")\n","        lam = 1\n","    else:\n","        if_freeze_bert = False\n","        lam = 0.6\n","        print(\"Bert is not freezed\")\n","    \n","    training_step_with_mixup(train_dataloader, model_mixup, optimizer, loss_fn, if_freeze_bert, lam)\n","    train_acc, train_f1 = validation_step(train_dataloader, model_mixup, loss_fn)\n","    val_acc, val_f1 = validation_step(eval_dataloader, model_mixup, loss_fn)\n","    \n","    print(\"Training results: \")\n","    print(\"Acc: {:.3f}, f1: {:.3f}\".format(train_acc, train_f1))\n","    \n","    print(\"Validation results: \")\n","    print(\"Acc: {:.3f}, f1: {:.3f}\".format(val_acc, val_f1))\n","    \n","    if val_acc > best_acc:\n","        best_acc = val_acc    \n","        torch.save(model, path)\n","        \n","best_acc"]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.execute_input":"2024-06-12T10:20:36.623828Z","iopub.status.busy":"2024-06-12T10:20:36.623512Z","iopub.status.idle":"2024-06-12T10:59:12.054313Z","shell.execute_reply":"2024-06-12T10:59:12.053285Z","shell.execute_reply.started":"2024-06-12T10:20:36.623802Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"05ac583392ba42e68219a8d07b343d75","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch: #1\n","Bert is freezed\n","Training results: \n","Acc: 0.568, f1: 0.545\n","Validation results: \n","Acc: 0.584, f1: 0.705\n","Epoch: #2\n","Bert is freezed\n","Training results: \n","Acc: 0.557, f1: 0.492\n","Validation results: \n","Acc: 0.571, f1: 0.649\n","Epoch: #3\n","Bert is freezed\n","Training results: \n","Acc: 0.572, f1: 0.526\n","Validation results: \n","Acc: 0.590, f1: 0.683\n","Epoch: #4\n","Bert is freezed\n","Training results: \n","Acc: 0.589, f1: 0.565\n","Validation results: \n","Acc: 0.590, f1: 0.704\n","Epoch: #5\n","Bert is freezed\n","Training results: \n","Acc: 0.603, f1: 0.602\n","Validation results: \n","Acc: 0.607, f1: 0.737\n","Epoch: #6\n","Bert is not freezed\n","Training results: \n","Acc: 0.860, f1: 0.859\n","Validation results: \n","Acc: 0.828, f1: 0.898\n","Epoch: #7\n","Bert is not freezed\n","Training results: \n","Acc: 0.919, f1: 0.919\n","Validation results: \n","Acc: 0.855, f1: 0.916\n","Epoch: #8\n","Bert is not freezed\n","Training results: \n","Acc: 0.938, f1: 0.937\n","Validation results: \n","Acc: 0.853, f1: 0.915\n","Epoch: #9\n","Bert is not freezed\n","Training results: \n","Acc: 0.949, f1: 0.949\n","Validation results: \n","Acc: 0.841, f1: 0.905\n","Epoch: #10\n","Bert is not freezed\n","Training results: \n","Acc: 0.969, f1: 0.969\n","Validation results: \n","Acc: 0.860, f1: 0.920\n","Epoch: #11\n","Bert is not freezed\n","mix_up_on\n","Training results: \n","Acc: 0.974, f1: 0.974\n","Validation results: \n","Acc: 0.853, f1: 0.916\n","Epoch: #12\n","Bert is not freezed\n","mix_up_on\n","Training results: \n","Acc: 0.974, f1: 0.975\n","Validation results: \n","Acc: 0.858, f1: 0.918\n","Epoch: #13\n","Bert is not freezed\n","mix_up_on\n","Training results: \n","Acc: 0.974, f1: 0.975\n","Validation results: \n","Acc: 0.850, f1: 0.911\n","Epoch: #14\n","Bert is not freezed\n","mix_up_on\n","Training results: \n","Acc: 0.983, f1: 0.983\n","Validation results: \n","Acc: 0.857, f1: 0.917\n","Epoch: #15\n","Bert is not freezed\n","mix_up_on\n","Training results: \n","Acc: 0.986, f1: 0.986\n","Validation results: \n","Acc: 0.852, f1: 0.915\n","Epoch: #16\n","Bert is not freezed\n","mix_up_on\n","Training results: \n","Acc: 0.978, f1: 0.977\n","Validation results: \n","Acc: 0.834, f1: 0.903\n","Epoch: #17\n","Bert is not freezed\n","mix_up_on\n","Training results: \n","Acc: 0.990, f1: 0.990\n","Validation results: \n","Acc: 0.859, f1: 0.918\n","Epoch: #18\n","Bert is not freezed\n","mix_up_on\n","Training results: \n","Acc: 0.988, f1: 0.988\n","Validation results: \n","Acc: 0.852, f1: 0.916\n","Epoch: #19\n","Bert is not freezed\n","mix_up_on\n","Training results: \n","Acc: 0.991, f1: 0.991\n","Validation results: \n","Acc: 0.852, f1: 0.913\n","Epoch: #20\n","Bert is not freezed\n","mix_up_on\n","Training results: \n","Acc: 0.989, f1: 0.989\n","Validation results: \n","Acc: 0.845, f1: 0.910\n"]},{"data":{"text/plain":["0.8600746268656716"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["model_mixup = BertWithClassifierMixUp(linear_size=hidden_layers)\n","model_mixup.to(device)\n","optimizer = AdamW(model_mixup.parameters(), lr=learning_rate)\n","loss_fn = nn.BCELoss()\n","\n","tqdm.pandas()\n","\n","best_acc, best_f1 = 0, 0\n","path = './best_model_with_mix.pt'\n","if_freeze_bert = False\n","lam = 1\n","\n","num_of_epochs = 20\n","\n","for i in tqdm(range(num_of_epochs)):\n","    print(\"Epoch: #{}\".format(i+1))\n","\n","    if i < 5:\n","        if_freeze_bert = True\n","        print(\"Bert is freezed\")\n","        lam = 1\n","    else:\n","        if_freeze_bert = False\n","        print(\"Bert is not freezed\")\n","    \n","    if i >= 10:\n","        lam = 0.9\n","        print(\"mix_up_on\")\n","        \n","    \n","    training_step_with_mixup(train_dataloader, model_mixup, optimizer, loss_fn, if_freeze_bert, lam)\n","    train_acc, train_f1 = validation_step(train_dataloader, model_mixup, loss_fn)\n","    val_acc, val_f1 = validation_step(eval_dataloader, model_mixup, loss_fn)\n","    \n","    print(\"Training results: \")\n","    print(\"Acc: {:.3f}, f1: {:.3f}\".format(train_acc, train_f1))\n","    \n","    print(\"Validation results: \")\n","    print(\"Acc: {:.3f}, f1: {:.3f}\".format(val_acc, val_f1))\n","    \n","    if val_acc > best_acc:\n","        best_acc = val_acc    \n","        torch.save(model_mixup, path)\n","        \n","best_acc"]},{"cell_type":"code","execution_count":53,"metadata":{"execution":{"iopub.execute_input":"2024-06-12T11:30:34.082135Z","iopub.status.busy":"2024-06-12T11:30:34.081805Z","iopub.status.idle":"2024-06-12T11:41:48.580447Z","shell.execute_reply":"2024-06-12T11:41:48.579497Z","shell.execute_reply.started":"2024-06-12T11:30:34.082110Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"39c9390c2aec4d01b98994ebc04b311d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/5 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch: #1\n","Training results: \n","Acc: 0.994, f1: 0.994\n","Validation results: \n","Acc: 0.854, f1: 0.916\n","Epoch: #2\n","Training results: \n","Acc: 0.994, f1: 0.994\n","Validation results: \n","Acc: 0.857, f1: 0.918\n","Epoch: #3\n","Training results: \n","Acc: 0.993, f1: 0.993\n","Validation results: \n","Acc: 0.856, f1: 0.917\n","Epoch: #4\n","Training results: \n","Acc: 0.995, f1: 0.995\n","Validation results: \n","Acc: 0.851, f1: 0.915\n","Epoch: #5\n","Training results: \n","Acc: 0.996, f1: 0.996\n","Validation results: \n","Acc: 0.850, f1: 0.913\n"]},{"data":{"text/plain":["0.8600746268656716"]},"execution_count":53,"metadata":{},"output_type":"execute_result"}],"source":["lam = 0.95\n","if_freeze_bert = False\n","\n","for i in tqdm(range(5)):\n","    print(\"Epoch: #{}\".format(i+1))\n","    \n","    training_step_with_mixup(train_dataloader, model_mixup, optimizer, loss_fn, if_freeze_bert, lam)\n","    train_acc, train_f1 = validation_step(train_dataloader, model_mixup, loss_fn)\n","    val_acc, val_f1 = validation_step(eval_dataloader, model_mixup, loss_fn)\n","    \n","    print(\"Training results: \")\n","    print(\"Acc: {:.3f}, f1: {:.3f}\".format(train_acc, train_f1))\n","    \n","    print(\"Validation results: \")\n","    print(\"Acc: {:.3f}, f1: {:.3f}\".format(val_acc, val_f1))\n","    \n","    if val_acc > best_acc:\n","        best_acc = val_acc    \n","        torch.save(model_mixup, path)\n","        \n","best_acc"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-06-12T12:30:34.415391Z","iopub.status.busy":"2024-06-12T12:30:34.415043Z","iopub.status.idle":"2024-06-12T12:53:09.800488Z","shell.execute_reply":"2024-06-12T12:53:09.799453Z","shell.execute_reply.started":"2024-06-12T12:30:34.415363Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d2044017177d4df18ce8386780db219e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/13 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch: #1\n","Bert is freezed\n","Training results: \n","Acc: 0.508, f1: 0.368\n","Validation results: \n","Acc: 0.504, f1: 0.507\n","Epoch: #2\n","Bert is freezed\n","Training results: \n","Acc: 0.538, f1: 0.441\n","Validation results: \n","Acc: 0.536, f1: 0.588\n","Epoch: #3\n","Bert is freezed\n","Training results: \n","Acc: 0.578, f1: 0.541\n","Validation results: \n","Acc: 0.581, f1: 0.681\n","Epoch: #4\n","Bert is freezed\n","Training results: \n","Acc: 0.554, f1: 0.476\n","Validation results: \n","Acc: 0.561, f1: 0.630\n","Epoch: #5\n","Bert is freezed\n","Training results: \n","Acc: 0.571, f1: 0.518\n","Validation results: \n","Acc: 0.574, f1: 0.656\n","Epoch: #6\n","Bert is not freezed\n","Training results: \n","Acc: 0.879, f1: 0.879\n","Validation results: \n","Acc: 0.850, f1: 0.912\n","Epoch: #7\n","Bert is not freezed\n","Training results: \n","Acc: 0.914, f1: 0.914\n","Validation results: \n","Acc: 0.860, f1: 0.920\n","Epoch: #8\n","Bert is not freezed\n","Training results: \n","Acc: 0.943, f1: 0.943\n","Validation results: \n","Acc: 0.855, f1: 0.916\n","Epoch: #9\n","Bert is not freezed\n","Training results: \n","Acc: 0.959, f1: 0.959\n","Validation results: \n","Acc: 0.852, f1: 0.914\n","Epoch: #10\n","Bert is not freezed\n","Training results: \n","Acc: 0.969, f1: 0.969\n","Validation results: \n","Acc: 0.859, f1: 0.919\n","Epoch: #11\n","Bert is not freezed\n","Training results: \n","Acc: 0.981, f1: 0.981\n","Validation results: \n","Acc: 0.859, f1: 0.919\n","Epoch: #12\n","Bert is not freezed\n","Training results: \n","Acc: 0.985, f1: 0.985\n","Validation results: \n","Acc: 0.854, f1: 0.915\n","Epoch: #13\n","Bert is not freezed\n","Training results: \n","Acc: 0.986, f1: 0.986\n","Validation results: \n","Acc: 0.845, f1: 0.910\n"]},{"data":{"text/plain":["0.8600746268656716"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["model_mixup = BertWithClassifierMixUp(linear_size=hidden_layers)\n","model_mixup.to(device)\n","optimizer = AdamW(model_mixup.parameters(), lr=learning_rate)\n","loss_fn = nn.BCELoss()\n","\n","tqdm.pandas()\n","\n","best_acc, best_f1 = 0, 0\n","path = './best_model.pt'\n","if_freeze_bert = False\n","lam = 1\n","\n","for i in tqdm(range(num_of_epochs)):\n","    print(\"Epoch: #{}\".format(i+1))\n","\n","    if i < 5:\n","        if_freeze_bert = True\n","        print(\"Bert is freezed\")\n","        lam = 1\n","    else:\n","        if_freeze_bert = False\n","        lam = 0.95\n","        print(\"Bert is not freezed\")\n","    \n","    training_step_with_mixup(train_dataloader, model_mixup, optimizer, loss_fn, if_freeze_bert, lam)\n","    train_acc, train_f1 = validation_step(train_dataloader, model_mixup, loss_fn)\n","    val_acc, val_f1 = validation_step(eval_dataloader, model_mixup, loss_fn)\n","    \n","    print(\"Training results: \")\n","    print(\"Acc: {:.3f}, f1: {:.3f}\".format(train_acc, train_f1))\n","    \n","    print(\"Validation results: \")\n","    print(\"Acc: {:.3f}, f1: {:.3f}\".format(val_acc, val_f1))\n","    \n","    if val_acc > best_acc:\n","        best_acc = val_acc    \n","        torch.save(model_mixup, path)\n","        \n","best_acc"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-06-12T12:56:09.677423Z","iopub.status.busy":"2024-06-12T12:56:09.676727Z","iopub.status.idle":"2024-06-12T13:18:47.923309Z","shell.execute_reply":"2024-06-12T13:18:47.922404Z","shell.execute_reply.started":"2024-06-12T12:56:09.677391Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"96fa2dafed0243d3803b74d456c162e2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/13 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch: #1\n","Bert is freezed\n","Training results: \n","Acc: 0.502, f1: 0.357\n","Validation results: \n","Acc: 0.497, f1: 0.496\n","Epoch: #2\n","Bert is freezed\n","Training results: \n","Acc: 0.503, f1: 0.360\n","Validation results: \n","Acc: 0.499, f1: 0.499\n","Epoch: #3\n","Bert is freezed\n","Training results: \n","Acc: 0.514, f1: 0.387\n","Validation results: \n","Acc: 0.503, f1: 0.512\n","Epoch: #4\n","Bert is freezed\n","Training results: \n","Acc: 0.541, f1: 0.459\n","Validation results: \n","Acc: 0.534, f1: 0.584\n","Epoch: #5\n","Bert is freezed\n","Training results: \n","Acc: 0.538, f1: 0.448\n","Validation results: \n","Acc: 0.534, f1: 0.578\n","Epoch: #6\n","Bert is not freezed\n","Training results: \n","Acc: 0.874, f1: 0.873\n","Validation results: \n","Acc: 0.838, f1: 0.906\n","Epoch: #7\n","Bert is not freezed\n","Training results: \n","Acc: 0.917, f1: 0.917\n","Validation results: \n","Acc: 0.855, f1: 0.917\n","Epoch: #8\n","Bert is not freezed\n","Training results: \n","Acc: 0.927, f1: 0.926\n","Validation results: \n","Acc: 0.838, f1: 0.904\n","Epoch: #9\n","Bert is not freezed\n","Training results: \n","Acc: 0.946, f1: 0.946\n","Validation results: \n","Acc: 0.851, f1: 0.913\n","Epoch: #10\n","Bert is not freezed\n","Training results: \n","Acc: 0.967, f1: 0.968\n","Validation results: \n","Acc: 0.852, f1: 0.915\n","Epoch: #11\n","Bert is not freezed\n","Training results: \n","Acc: 0.964, f1: 0.964\n","Validation results: \n","Acc: 0.825, f1: 0.895\n","Epoch: #12\n","Bert is not freezed\n","Training results: \n","Acc: 0.973, f1: 0.973\n","Validation results: \n","Acc: 0.821, f1: 0.894\n","Epoch: #13\n","Bert is not freezed\n","Training results: \n","Acc: 0.977, f1: 0.977\n","Validation results: \n","Acc: 0.829, f1: 0.900\n"]},{"data":{"text/plain":["0.855410447761194"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["model_mixup = BertWithClassifierMixUp(linear_size=hidden_layers)\n","model_mixup.to(device)\n","optimizer = AdamW(model_mixup.parameters(), lr=learning_rate)\n","loss_fn = nn.BCELoss()\n","\n","tqdm.pandas()\n","\n","best_acc, best_f1 = 0, 0\n","path = './best_model.pt'\n","if_freeze_bert = False\n","lam = 1\n","\n","for i in tqdm(range(num_of_epochs)):\n","    print(\"Epoch: #{}\".format(i+1))\n","\n","    if i < 5:\n","        if_freeze_bert = True\n","        print(\"Bert is freezed\")\n","        lam = 1\n","    else:\n","        if_freeze_bert = False\n","        lam = 1\n","        print(\"Bert is not freezed\")\n","    \n","    training_step_with_mixup(train_dataloader, model_mixup, optimizer, loss_fn, if_freeze_bert, lam)\n","    train_acc, train_f1 = validation_step(train_dataloader, model_mixup, loss_fn)\n","    val_acc, val_f1 = validation_step(eval_dataloader, model_mixup, loss_fn)\n","    \n","    print(\"Training results: \")\n","    print(\"Acc: {:.3f}, f1: {:.3f}\".format(train_acc, train_f1))\n","    \n","    print(\"Validation results: \")\n","    print(\"Acc: {:.3f}, f1: {:.3f}\".format(val_acc, val_f1))\n","    \n","    if val_acc > best_acc:\n","        best_acc = val_acc    \n","        torch.save(model, path)\n","        \n","best_acc"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T06:35:33.708700Z","iopub.status.busy":"2024-06-14T06:35:33.707898Z","iopub.status.idle":"2024-06-14T06:35:33.876240Z","shell.execute_reply":"2024-06-14T06:35:33.875505Z","shell.execute_reply.started":"2024-06-14T06:35:33.708670Z"},"trusted":true},"outputs":[],"source":["from torch import nn\n","\n","in_features = 768\n","tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n","\n","class BertWithClassifierMixUp(nn.Module):\n","    def __init__(self, linear_size):\n","        super(BertWithClassifierMixUp, self).__init__()\n","        self.bert = BertModel.from_pretrained(\"bert-base-cased\")\n","        self.head = nn.Sequential(\n","            nn.Dropout(),\n","            nn.Linear(in_features=in_features, out_features=linear_size),\n","            nn.BatchNorm1d(num_features=linear_size),\n","            nn.Dropout(p=0.8),\n","            nn.Linear(in_features=linear_size, out_features=1),\n","            # nn.BatchNorm1d(num_features=1),\n","            nn.Sigmoid()\n","        )\n","        \n","#     def forward(self, tokens, attention_mask):\n","#         bert_output = self.bert(input_ids=tokens, attention_mask=attention_mask)\n","#         y = self.head(bert_output[1]) \n","#         return y\n","    \n","    def forward(self, tokens1, attention_mask1, tokens2, attention_mask2, lam):\n","        bert_output1 = self.bert(input_ids=tokens1, attention_mask=attention_mask1)\n","        bert_output2 = self.bert(input_ids=tokens2, attention_mask=attention_mask2)\n","    \n","        bert_output = lam * bert_output1[1] + (1.0 - lam) * bert_output2[1]\n","    \n","        y = self.head(bert_output) \n","        return y\n","        \n","    def freeze_bert(self):\n","        for param in self.bert.named_parameters():\n","            param[1].requires_grad=False\n","    \n","    def unfreeze_bert(self):\n","        for param in self.bert.named_parameters():\n","            param[1].requires_grad=True\n","\n"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T06:35:35.577149Z","iopub.status.busy":"2024-06-14T06:35:35.576660Z","iopub.status.idle":"2024-06-14T06:35:35.586635Z","shell.execute_reply":"2024-06-14T06:35:35.585596Z","shell.execute_reply.started":"2024-06-14T06:35:35.577117Z"},"trusted":true},"outputs":[],"source":["def training_step_with_mixup(dataloader, model, optimizer, loss_fn, if_freeze_bert, lam):\n","    \"\"\"Method to train the model\"\"\"\n","    \n","    model.train()\n","    model.freeze_bert() if if_freeze_bert else model.unfreeze_bert()\n","      \n","    epoch_loss = 0\n","    size = len(dataloader.dataset)\n"," \n","    for i, batch in enumerate(dataloader):\n","        \n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['labels'].to(device)\n","\n","        indexes = torch.randperm(len(input_ids)).to(device)\n","#         print(input_ids.shape)\n","    \n","        model_answer = model(input_ids, attention_mask, input_ids[indexes], attention_mask[indexes], lam)\n","    \n","        outputs = torch.flatten(model_answer)\n","        \n","        mixup_labels = lam * labels.float() + (1.0 - lam) * labels.float()[indexes]\n","        \n","        optimizer.zero_grad()\n","        loss = loss_fn(outputs, mixup_labels)\n","        epoch_loss += loss.item()\n","        loss.backward()\n","        optimizer.step()"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T06:35:36.579062Z","iopub.status.busy":"2024-06-14T06:35:36.578206Z","iopub.status.idle":"2024-06-14T06:35:36.586024Z","shell.execute_reply":"2024-06-14T06:35:36.584992Z","shell.execute_reply.started":"2024-06-14T06:35:36.579029Z"},"trusted":true},"outputs":[],"source":["def validation_step_mixup(dataloader, model, loss_fn):\n","    \"\"\"Method to test the model's accuracy and loss on the validation set\"\"\"\n","    \n","    model.eval()\n","    model.freeze_bert()\n","    \n","    size = len(dataloader)\n","    f1, acc = 0, 0\n","    \n","    with torch.no_grad():\n","        for batch in dataloader:\n","            X = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            y = batch['labels'].to(device)\n","                  \n","            pred = model(X, attention_mask, X, attention_mask, 1)\n","            \n","            acc_batch, f1_batch = eval_prediction(y.float(), pred)                        \n","            acc += acc_batch\n","            f1 += f1_batch\n","\n","        acc = acc/size\n","        f1 = f1/size\n","                \n","    return acc, f1"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T20:05:11.776056Z","iopub.status.busy":"2024-06-13T20:05:11.775195Z","iopub.status.idle":"2024-06-13T20:34:18.226131Z","shell.execute_reply":"2024-06-13T20:34:18.225191Z","shell.execute_reply.started":"2024-06-13T20:05:11.776023Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a83b750191d444c1b3c4777d2f961d88","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/13 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch: #1\n","Bert is freezed\n","Training results: \n","Acc: 0.500, f1: 0.351\n","Validation results: \n","Acc: 0.497, f1: 0.496\n","Epoch: #2\n","Bert is freezed\n","Training results: \n","Acc: 0.515, f1: 0.387\n","Validation results: \n","Acc: 0.504, f1: 0.518\n","Epoch: #3\n","Bert is freezed\n","Training results: \n","Acc: 0.541, f1: 0.451\n","Validation results: \n","Acc: 0.528, f1: 0.578\n","Epoch: #4\n","Bert is not freezed\n","Training results: \n","Acc: 0.855, f1: 0.854\n","Validation results: \n","Acc: 0.832, f1: 0.902\n","Epoch: #5\n","Bert is not freezed\n","Training results: \n","Acc: 0.918, f1: 0.918\n","Validation results: \n","Acc: 0.848, f1: 0.913\n","Epoch: #6\n","Bert is not freezed\n","Training results: \n","Acc: 0.949, f1: 0.949\n","Validation results: \n","Acc: 0.865, f1: 0.922\n","Epoch: #7\n","Bert is not freezed\n","Mix Up\n","Training results: \n","Acc: 0.959, f1: 0.959\n","Validation results: \n","Acc: 0.860, f1: 0.920\n","Epoch: #8\n","Bert is not freezed\n","Mix Up\n","Training results: \n","Acc: 0.965, f1: 0.965\n","Validation results: \n","Acc: 0.839, f1: 0.906\n","Epoch: #9\n","Bert is not freezed\n","Mix Up\n","Training results: \n","Acc: 0.976, f1: 0.976\n","Validation results: \n","Acc: 0.854, f1: 0.915\n","Epoch: #10\n","Bert is not freezed\n","Mix Up\n","Training results: \n","Acc: 0.980, f1: 0.980\n","Validation results: \n","Acc: 0.850, f1: 0.913\n","Epoch: #11\n","Bert is not freezed\n","Mix Up\n","Training results: \n","Acc: 0.985, f1: 0.985\n","Validation results: \n","Acc: 0.851, f1: 0.914\n","Epoch: #12\n","Bert is not freezed\n","Mix Up\n","Training results: \n","Acc: 0.988, f1: 0.988\n","Validation results: \n","Acc: 0.854, f1: 0.917\n","Epoch: #13\n","Bert is not freezed\n","Mix Up\n","Training results: \n","Acc: 0.988, f1: 0.988\n","Validation results: \n","Acc: 0.851, f1: 0.913\n"]},{"data":{"text/plain":["0.8647388059701493"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["model_mixup = BertWithClassifierMixUp(linear_size=hidden_layers)\n","model_mixup.to(device)\n","optimizer = AdamW(model_mixup.parameters(), lr=learning_rate)\n","loss_fn = nn.BCELoss()\n","\n","tqdm.pandas()\n","\n","best_acc, best_f1 = 0, 0\n","path = './best_model.pt'\n","if_freeze_bert = False\n","lam = 1\n","\n","for i in tqdm(range(num_of_epochs)):\n","    print(\"Epoch: #{}\".format(i+1))\n","\n","    if i < 3:\n","        if_freeze_bert = True\n","        print(\"Bert is freezed\")\n","        lam = 1\n","    else:\n","        if_freeze_bert = False\n","        print(\"Bert is not freezed\")\n","        \n","    if i >= 6:\n","        print(\"Mix Up\")\n","        lam = 0.9\n","    \n","    training_step_with_mixup(train_dataloader, model_mixup, optimizer, loss_fn, if_freeze_bert, lam)\n","    train_acc, train_f1 = validation_step_mixup(train_dataloader, model_mixup, loss_fn)\n","    val_acc, val_f1 = validation_step_mixup(eval_dataloader, model_mixup, loss_fn)\n","    \n","    print(\"Training results: \")\n","    print(\"Acc: {:.3f}, f1: {:.3f}\".format(train_acc, train_f1))\n","    \n","    print(\"Validation results: \")\n","    print(\"Acc: {:.3f}, f1: {:.3f}\".format(val_acc, val_f1))\n","    \n","    if val_acc > best_acc:\n","        best_acc = val_acc    \n","#         torch.save(model_mixup, path)\n","        \n","best_acc"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T06:35:44.800314Z","iopub.status.busy":"2024-06-14T06:35:44.799940Z","iopub.status.idle":"2024-06-14T07:04:40.381089Z","shell.execute_reply":"2024-06-14T07:04:40.380128Z","shell.execute_reply.started":"2024-06-14T06:35:44.800284Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a7dee135b5ff46b79bfbd69413a78ba4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/13 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch: #1\n","Bert is freezed\n","Training results: \n","Acc: 0.501, f1: 0.360\n","Validation results: \n","Acc: 0.501, f1: 0.506\n","Epoch: #2\n","Bert is freezed\n","Training results: \n","Acc: 0.563, f1: 0.539\n","Validation results: \n","Acc: 0.559, f1: 0.673\n","Epoch: #3\n","Bert is freezed\n","Training results: \n","Acc: 0.576, f1: 0.560\n","Validation results: \n","Acc: 0.571, f1: 0.692\n","Epoch: #4\n","Bert is not freezed\n","Training results: \n","Acc: 0.885, f1: 0.885\n","Validation results: \n","Acc: 0.840, f1: 0.907\n","Epoch: #5\n","Bert is not freezed\n","Training results: \n","Acc: 0.926, f1: 0.925\n","Validation results: \n","Acc: 0.848, f1: 0.912\n","Epoch: #6\n","Bert is not freezed\n","Training results: \n","Acc: 0.948, f1: 0.948\n","Validation results: \n","Acc: 0.856, f1: 0.918\n","Epoch: #7\n","Bert is not freezed\n","Mix Up\n","Training results: \n","Acc: 0.952, f1: 0.952\n","Validation results: \n","Acc: 0.836, f1: 0.903\n","Epoch: #8\n","Bert is not freezed\n","Mix Up\n","Training results: \n","Acc: 0.965, f1: 0.965\n","Validation results: \n","Acc: 0.855, f1: 0.917\n","Epoch: #9\n","Bert is not freezed\n","Mix Up\n","Training results: \n","Acc: 0.971, f1: 0.971\n","Validation results: \n","Acc: 0.860, f1: 0.919\n","Epoch: #10\n","Bert is not freezed\n","Mix Up\n","Training results: \n","Acc: 0.975, f1: 0.975\n","Validation results: \n","Acc: 0.852, f1: 0.916\n","Epoch: #11\n","Bert is not freezed\n","Mix Up\n","Training results: \n","Acc: 0.976, f1: 0.976\n","Validation results: \n","Acc: 0.851, f1: 0.915\n","Epoch: #12\n","Bert is not freezed\n","Mix Up\n","Training results: \n","Acc: 0.978, f1: 0.978\n","Validation results: \n","Acc: 0.850, f1: 0.913\n","Epoch: #13\n","Bert is not freezed\n","Mix Up\n","Training results: \n","Acc: 0.979, f1: 0.979\n","Validation results: \n","Acc: 0.835, f1: 0.904\n"]},{"data":{"text/plain":["0.8600746268656716"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["model_mixup = BertWithClassifierMixUp(linear_size=hidden_layers)\n","model_mixup.to(device)\n","optimizer = AdamW(model_mixup.parameters(), lr=learning_rate)\n","loss_fn = nn.BCELoss()\n","\n","tqdm.pandas()\n","\n","best_acc, best_f1 = 0, 0\n","path = './best_model.pt'\n","if_freeze_bert = False\n","lam = 1\n","\n","num_of_epochs= 13\n","\n","for i in tqdm(range(num_of_epochs)):\n","    print(\"Epoch: #{}\".format(i+1))\n","\n","    if i < 3:\n","        if_freeze_bert = True\n","        print(\"Bert is freezed\")\n","        lam = 1\n","    else:\n","        if_freeze_bert = False\n","        print(\"Bert is not freezed\")\n","        \n","    if i >= 6:\n","        print(\"Mix Up\")\n","        lam = 0.5\n","    \n","    training_step_with_mixup(train_dataloader, model_mixup, optimizer, loss_fn, if_freeze_bert, lam)\n","    train_acc, train_f1 = validation_step_mixup(train_dataloader, model_mixup, loss_fn)\n","    val_acc, val_f1 = validation_step_mixup(eval_dataloader, model_mixup, loss_fn)\n","    \n","    print(\"Training results: \")\n","    print(\"Acc: {:.3f}, f1: {:.3f}\".format(train_acc, train_f1))\n","    \n","    print(\"Validation results: \")\n","    print(\"Acc: {:.3f}, f1: {:.3f}\".format(val_acc, val_f1))\n","    \n","    if val_acc > best_acc:\n","        best_acc = val_acc    \n","        torch.save(model_mixup, path)\n","        \n","best_acc"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T21:07:28.434044Z","iopub.status.busy":"2024-06-13T21:07:28.433755Z","iopub.status.idle":"2024-06-13T21:18:53.724747Z","shell.execute_reply":"2024-06-13T21:18:53.723806Z","shell.execute_reply.started":"2024-06-13T21:07:28.434020Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d2baef1f1623488bbb99c9cc80086a8b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/6 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch: #1\n","Bert is freezed\n","Training results: \n","Acc: 0.550, f1: 0.484\n","Validation results: \n","Acc: 0.533, f1: 0.601\n","Epoch: #2\n","Bert is freezed\n","Training results: \n","Acc: 0.610, f1: 0.611\n","Validation results: \n","Acc: 0.614, f1: 0.743\n","Epoch: #3\n","Bert is freezed\n","Training results: \n","Acc: 0.603, f1: 0.586\n","Validation results: \n","Acc: 0.617, f1: 0.732\n","Epoch: #4\n","Bert is not freezed\n","Training results: \n","Acc: 0.879, f1: 0.878\n","Validation results: \n","Acc: 0.848, f1: 0.913\n","Epoch: #5\n","Bert is not freezed\n","Training results: \n","Acc: 0.919, f1: 0.919\n","Validation results: \n","Acc: 0.853, f1: 0.914\n","Epoch: #6\n","Bert is not freezed\n","Training results: \n","Acc: 0.922, f1: 0.922\n","Validation results: \n","Acc: 0.825, f1: 0.893\n"]},{"data":{"text/plain":["0.8526119402985075"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["model_mixup = BertWithClassifierMixUp(linear_size=hidden_layers)\n","model_mixup.to(device)\n","optimizer = AdamW(model_mixup.parameters(), lr=learning_rate)\n","loss_fn = nn.BCELoss()\n","\n","tqdm.pandas()\n","\n","best_acc, best_f1 = 0, 0\n","path = './best_model.pt'train_dataloader\n","if_freeze_bert = False\n","lam = 1\n","\n","num_of_epochs = 6\n","\n","for i in tqdm(range(num_of_epochs)):\n","    print(\"Epoch: #{}\".format(i+1))\n","\n","    if i < 3:\n","        if_freeze_bert = True\n","        print(\"Bert is freezed\")\n","        lam = 1\n","    else:\n","        if_freeze_bert = False\n","        lam = 0.9\n","        print(\"Bert is not freezed\")\n","        \n","    \n","    training_step_with_mixup(train_dataloader, model_mixup, optimizer, loss_fn, if_freeze_bert, lam)\n","    train_acc, train_f1 = validation_step_mixup(train_dataloader, model_mixup, loss_fn)\n","    val_acc, val_f1 = validation_step_mixup(eval_dataloader, model_mixup, loss_fn)\n","    \n","    print(\"Training results: \")\n","    print(\"Acc: {:.3f}, f1: {:.3f}\".format(train_acc, train_f1))\n","    \n","    print(\"Validation results: \")\n","    print(\"Acc: {:.3f}, f1: {:.3f}\".format(val_acc, val_f1))\n","    \n","    if val_acc > best_acc:\n","        best_acc = val_acc    \n","#         torch.save(model_mixup, path)\n","        \n","best_acc"]},{"cell_type":"markdown","metadata":{},"source":["Финальные метрики"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T07:20:50.465912Z","iopub.status.busy":"2024-06-14T07:20:50.465536Z","iopub.status.idle":"2024-06-14T07:20:50.810437Z","shell.execute_reply":"2024-06-14T07:20:50.809636Z","shell.execute_reply.started":"2024-06-14T07:20:50.465881Z"},"trusted":true},"outputs":[],"source":["model_mixup = torch.load(\"/kaggle/working/best_model.pt\")"]},{"cell_type":"code","execution_count":52,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T07:39:42.414568Z","iopub.status.busy":"2024-06-14T07:39:42.414263Z","iopub.status.idle":"2024-06-14T07:39:42.422381Z","shell.execute_reply":"2024-06-14T07:39:42.421464Z","shell.execute_reply.started":"2024-06-14T07:39:42.414543Z"},"trusted":true},"outputs":[],"source":["test_dataloader = DataLoader(\n","    tokenized_datasets['test'], shuffle=True, batch_size=8, collate_fn=data_collator\n",")"]},{"cell_type":"code","execution_count":53,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T07:39:44.839409Z","iopub.status.busy":"2024-06-14T07:39:44.839030Z","iopub.status.idle":"2024-06-14T07:39:49.383298Z","shell.execute_reply":"2024-06-14T07:39:49.382303Z","shell.execute_reply.started":"2024-06-14T07:39:44.839378Z"},"trusted":true},"outputs":[],"source":["acc, f1 = validation_step_mixup(test_dataloader, model_mixup, loss_fn)"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T07:21:39.090443Z","iopub.status.busy":"2024-06-14T07:21:39.090094Z","iopub.status.idle":"2024-06-14T07:21:39.095593Z","shell.execute_reply":"2024-06-14T07:21:39.094802Z","shell.execute_reply.started":"2024-06-14T07:21:39.090414Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["acc=0.8460820895522388, f1=0.8468752847484188\n"]}],"source":["print(f\"{acc=}, {f1=}\")"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30732,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
